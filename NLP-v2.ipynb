{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import re\n",
    "import keras\n",
    "\n",
    "#import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "#import matplotlib.pyplot as pylab\n",
    "#import seaborn as sns\n",
    "#import plotly.offline as py\n",
    "#import plotly.graph_objs as go\n",
    "#py.init_notebook_mode(connected=True)\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, GRU, Flatten\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D, Conv1D, GlobalAveragePooling1D, concatenate\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.models import Model\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "from keras.callbacks import CSVLogger, ReduceLROnPlateau, ModelCheckpoint \n",
    "\n",
    "import pickle\n",
    "#import nltk\n",
    "#import string\n",
    "#from nltk.corpus import stopwords\n",
    "#from sklearn.manifold import TSNE\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "#from sklearn.metrics import f1_score, roc_auc_score, multilabel_confusion_matrix, average_precision_score, precision_recall_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset and Basic EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List Classifier\n",
    "train_labels = ['outwear','top','trousers','women dresses','women skirts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>word_representation</th>\n",
       "      <th>outwear</th>\n",
       "      <th>top</th>\n",
       "      <th>trousers</th>\n",
       "      <th>women dresses</th>\n",
       "      <th>women skirts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>w7718 w173355 w138132 w232277 w90685 w314686 w...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>w195317 w127737 w171593 w22890 w342007 w217871...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>w247655 w270233 w261113 w337250 w366000 w37873...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>w279289 w395855 w61795 w286461 w308610 w27013 ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>w254516 w135431 w115724 w331534 w256214 w71240...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>w53495 w306061 w372126 w47982 w66980 w189406 w...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>w237465 w256553 w286461 w382662 w206066 w12125...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>w173317 w39222 w207614 w136665 w394246 w197783...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>w373517 w37419 w358253 w162965 w286461 w204762...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>w230409 w109269 w369689 w186076 w377961 w21787...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                word_representation  outwear  top  \\\n",
       "0   0  w7718 w173355 w138132 w232277 w90685 w314686 w...        1    0   \n",
       "1   1  w195317 w127737 w171593 w22890 w342007 w217871...        1    0   \n",
       "2   2  w247655 w270233 w261113 w337250 w366000 w37873...        0    1   \n",
       "3   3  w279289 w395855 w61795 w286461 w308610 w27013 ...        1    0   \n",
       "4   4  w254516 w135431 w115724 w331534 w256214 w71240...        1    0   \n",
       "5   5  w53495 w306061 w372126 w47982 w66980 w189406 w...        1    0   \n",
       "6   6  w237465 w256553 w286461 w382662 w206066 w12125...        1    0   \n",
       "7   7  w173317 w39222 w207614 w136665 w394246 w197783...        1    1   \n",
       "8   8  w373517 w37419 w358253 w162965 w286461 w204762...        1    0   \n",
       "9   9  w230409 w109269 w369689 w186076 w377961 w21787...        1    1   \n",
       "\n",
       "   trousers  women dresses  women skirts  \n",
       "0         1              0             0  \n",
       "1         1              0             0  \n",
       "2         1              0             0  \n",
       "3         1              0             0  \n",
       "4         1              0             0  \n",
       "5         0              0             1  \n",
       "6         0              1             0  \n",
       "7         1              0             0  \n",
       "8         0              0             0  \n",
       "9         0              0             0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading csv file of train set\n",
    "fashion_df = pd.read_csv(\"./datasets/TIL_NLP_train_dataset.csv\")\n",
    "fashion_df.dropna(inplace=True)\n",
    "fashion_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>word_representation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>w373517 w383437 w374393 w87179 w289496 w327385...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>w237465 w167111 w279437 w194870 w351537 w17560...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>w151648 w93366 w121255 w193800 w71240 w48576 w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>w182664 w317736 w33852 w111248 w45374 w209361 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>w206647 w236725 w99560 w338476 w75409 w36882 w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>w256553 w182887 w239430 w96414 w276473 w217871...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>w305957 w254429 w215751 w155034 w287643 w45765...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>w318673 w350483 w356690 w186076 w151648 w34893...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>w500001 w128292 w253354 w254516 w102910 w37439...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>w41024 w237465 w95569 w174897 w103096 w237465 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                word_representation\n",
       "0   0  w373517 w383437 w374393 w87179 w289496 w327385...\n",
       "1   1  w237465 w167111 w279437 w194870 w351537 w17560...\n",
       "2   2  w151648 w93366 w121255 w193800 w71240 w48576 w...\n",
       "3   3  w182664 w317736 w33852 w111248 w45374 w209361 ...\n",
       "4   4  w206647 w236725 w99560 w338476 w75409 w36882 w...\n",
       "5   5  w256553 w182887 w239430 w96414 w276473 w217871...\n",
       "6   6  w305957 w254429 w215751 w155034 w287643 w45765...\n",
       "7   7  w318673 w350483 w356690 w186076 w151648 w34893...\n",
       "8   8  w500001 w128292 w253354 w254516 w102910 w37439...\n",
       "9   9  w41024 w237465 w95569 w174897 w103096 w237465 ..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading csv file of test set\n",
    "fashion_test_df = pd.read_csv(\"./datasets/TIL_NLP_test_dataset.csv\")\n",
    "fashion_test_df.dropna(inplace=True)\n",
    "fashion_test_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most number of words in a sentence: 47\n"
     ]
    }
   ],
   "source": [
    "# Get the sentence with the most number of words and count how many words are there in the sentence\n",
    "fashion_df_numpy = np.asarray(fashion_df)\n",
    "\n",
    "# -----  DEBUG  -----\n",
    "#fashion_df_numpy[0]\n",
    "#fashion_df_numpy[2][1] \n",
    "# -----  DEBUG END -----\n",
    "\n",
    "max_len = 0 # initialise 0 to the maximum number of words in a sentence\n",
    "for i,j in enumerate(fashion_df_numpy):\n",
    "    string = fashion_df_numpy[i][1]\n",
    "    substring = 'w'\n",
    "    count = string.count(substring)\n",
    "    if count > max_len:\n",
    "        max_len = count\n",
    "print('Most number of words in a sentence: {}'.format(max_len))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence we can set the max length parameter to 50 (a number near 47) for pad_sequences for the Tokenizing portion of the EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of Train Set\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 7380 entries, 0 to 7379\n",
      "Data columns (total 7 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   id                   7380 non-null   int64 \n",
      " 1   word_representation  7380 non-null   object\n",
      " 2   outwear              7380 non-null   int64 \n",
      " 3   top                  7380 non-null   int64 \n",
      " 4   trousers             7380 non-null   int64 \n",
      " 5   women dresses        7380 non-null   int64 \n",
      " 6   women skirts         7380 non-null   int64 \n",
      "dtypes: int64(6), object(1)\n",
      "memory usage: 461.2+ KB\n",
      "\n",
      "Information of Test Set\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2460 entries, 0 to 2459\n",
      "Data columns (total 2 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   id                   2460 non-null   int64 \n",
      " 1   word_representation  2460 non-null   object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 57.7+ KB\n"
     ]
    }
   ],
   "source": [
    "#This displays the relevant information of the dataframe\n",
    "#Train Set\n",
    "print(\"Information of Train Set\\n\")\n",
    "fashion_df.info()\n",
    "#Test Set\n",
    "print(\"\\nInformation of Test Set\\n\")\n",
    "fashion_test_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dictionary back from the pickle file.\n",
    "words = pickle.load( open( \"./datasets/word_embeddings.pkl\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing out random mask:  [-0.60916    0.61913    0.13121    0.1316     0.64012    0.68684\n",
      " -0.3921     0.9382    -0.11713   -0.80938   -0.12969    0.49683\n",
      " -0.23817   -0.50883   -0.043889  -0.22279   -0.54817    0.43512\n",
      "  0.56917   -0.16795   -0.034313   0.58262    0.0060361 -0.67505\n",
      "  0.39798    0.59964   -0.086458   0.13071   -0.019007  -0.66493\n",
      " -0.20891   -0.67784   -0.19218   -0.74873   -0.29443    0.26081\n",
      " -0.27792   -0.56025    0.49356    0.12164   -0.11087    0.43585\n",
      " -0.43406    0.074474   0.21458   -0.2306    -0.15315    0.023675\n",
      "  0.22277    0.029242   0.3213    -0.1201     0.16719    0.45513\n",
      "  0.78812   -1.4279     0.74593   -0.025132   0.53096    0.27388\n",
      " -0.1441     0.37418   -0.089216  -0.68374    1.0245    -0.080028\n",
      "  0.93712   -1.0687    -0.20928   -0.13549   -0.049717  -0.041891\n",
      "  0.3116    -0.20401   -0.18139    0.59803    0.11361   -0.2322\n",
      " -0.78788    0.131      0.85614    0.2313     0.24198    0.48671\n",
      " -1.1756     0.18617   -0.50984   -0.15334   -0.30589   -0.10215\n",
      " -0.044135   0.92753   -0.5065    -0.19236    0.026153  -1.0069\n",
      " -0.12455   -0.16333    0.35281    0.68593  ]\n"
     ]
    }
   ],
   "source": [
    "print(\"Printing out random mask: \",words[\"w7777\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The vocabulary size is: 400000\n"
     ]
    }
   ],
   "source": [
    "# Chec the vocabulary size of the dataset\n",
    "vocabulary_size = len(words)\n",
    "print(\"The vocabulary size is: {}\".format(vocabulary_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7380, 35159)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = map(''.join, fashion_df[['word_representation']].values.tolist())\n",
    "\n",
    "#instantiate CountVectorizer()\n",
    "cv=CountVectorizer(stop_words=\"english\", analyzer='word', \n",
    "                             ngram_range=(1, 2), max_df=1.0, min_df=1, max_features=None)\n",
    " \n",
    "# this steps generates word counts for the words in your docs\n",
    "word_count_vector=cv.fit_transform(docs)\n",
    "word_count_vector.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use IDF & TF-IDF to check how relevant the 'masked' word is in a given document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the TF-IDF transformer\n",
    "tfidf_transformer=TfidfTransformer(smooth_idf=True,use_idf=True)\n",
    "tfidf_transformer.fit(word_count_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>w34893</th>\n",
       "      <td>1.756196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w194870</th>\n",
       "      <td>2.044937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w217871</th>\n",
       "      <td>2.147904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w311583</th>\n",
       "      <td>2.234838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w186076</th>\n",
       "      <td>2.321383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w241910</th>\n",
       "      <td>2.481903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w120979</th>\n",
       "      <td>2.547197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w66980</th>\n",
       "      <td>2.658872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w286461</th>\n",
       "      <td>2.711477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w250138</th>\n",
       "      <td>2.718252</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              idf\n",
       "w34893   1.756196\n",
       "w194870  2.044937\n",
       "w217871  2.147904\n",
       "w311583  2.234838\n",
       "w186076  2.321383\n",
       "w241910  2.481903\n",
       "w120979  2.547197\n",
       "w66980   2.658872\n",
       "w286461  2.711477\n",
       "w250138  2.718252"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print idf values\n",
    "df_idf = pd.DataFrame(tfidf_transformer.idf_, index=cv.get_feature_names(),columns=['idf'])\n",
    " \n",
    "# sort ascending\n",
    "df_idf = df_idf.sort_values(by=['idf'])\n",
    "df_idf.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>w172358 w66535</th>\n",
       "      <td>0.226660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w136109 w172358</th>\n",
       "      <td>0.226660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w66535 w80220</th>\n",
       "      <td>0.226660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w66535</th>\n",
       "      <td>0.209608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w173355 w138132</th>\n",
       "      <td>0.204119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w80220 w255783</th>\n",
       "      <td>0.204119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w138132 w232277</th>\n",
       "      <td>0.204119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w7718 w173355</th>\n",
       "      <td>0.199633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w255783 w15393</th>\n",
       "      <td>0.195841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w173355</th>\n",
       "      <td>0.192556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w232277 w90685</th>\n",
       "      <td>0.189659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w90685 w314686</th>\n",
       "      <td>0.189659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w220790 w207614</th>\n",
       "      <td>0.189659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w314686 w256905</th>\n",
       "      <td>0.184722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w232277</th>\n",
       "      <td>0.160040</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    tfidf\n",
       "w172358 w66535   0.226660\n",
       "w136109 w172358  0.226660\n",
       "w66535 w80220    0.226660\n",
       "w66535           0.209608\n",
       "w173355 w138132  0.204119\n",
       "w80220 w255783   0.204119\n",
       "w138132 w232277  0.204119\n",
       "w7718 w173355    0.199633\n",
       "w255783 w15393   0.195841\n",
       "w173355          0.192556\n",
       "w232277 w90685   0.189659\n",
       "w90685 w314686   0.189659\n",
       "w220790 w207614  0.189659\n",
       "w314686 w256905  0.184722\n",
       "w232277          0.160040"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count matrix\n",
    "docs = map(''.join, fashion_df[['word_representation']].values.tolist())\n",
    "count_vector=cv.transform(docs)\n",
    "\n",
    "# tf-idf scores\n",
    "tf_idf_vector=tfidf_transformer.transform(count_vector)\n",
    "\n",
    "feature_names = cv.get_feature_names()\n",
    " \n",
    "#get tfidf vector for first document\n",
    "first_document_vector=tf_idf_vector[0]\n",
    " \n",
    "#print the scores\n",
    "df = pd.DataFrame(first_document_vector.T.todense(), index=feature_names, columns=[\"tfidf\"])\n",
    "df = df.sort_values(by=[\"tfidf\"],ascending=False)\n",
    "df.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTANTS FOR TOKENIZING AND TRAINING OF MODEL\n",
    "MAX_FEATURES = 20000\n",
    "MAX_LENGTH = 50\n",
    "EMBED_SIZE = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE A TOKENIZER INSTANCE\n",
    "tokenizer = Tokenizer(num_words=MAX_FEATURES)\n",
    "tokenizer.fit_on_texts(fashion_df['word_representation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOKENIZED THE TRAIN AND TEST SET FEATURES\n",
    "train_tokenized = tokenizer.texts_to_sequences(fashion_df['word_representation'])\n",
    "test_tokenized = tokenizer.texts_to_sequences(fashion_test_df['word_representation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PAD SEQUENCES TO THE SAME LENGTH FOR THE FEATURES (SENTENCES/WORD REPRESENTATION)\n",
    "X_train = pad_sequences(train_tokenized, maxlen=MAX_LENGTH)\n",
    "X_test = pad_sequences(test_tokenized, maxlen=MAX_LENGTH)\n",
    "\n",
    "# TRAIN LABELS\n",
    "y_train = fashion_df[train_labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DECLARE MODEL\n",
    "model = Sequential([\n",
    "    Embedding(MAX_FEATURES, EMBED_SIZE),\n",
    "    Bidirectional(LSTM(64,return_sequences=True,dropout=0.1,recurrent_dropout=0.1)),\n",
    "    GlobalMaxPool1D(),\n",
    "    Dropout(0.1),\n",
    "    Dense(32,activation='relu'),\n",
    "    Dropout(0.1),\n",
    "    Dense(5,activation=\"sigmoid\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 50)          1000000   \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, None, 128)         58880     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 165       \n",
      "=================================================================\n",
      "Total params: 1,063,173\n",
      "Trainable params: 1,063,173\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note down the useful informations into a .csv file\n",
    "csv_logger = CSVLogger('./datasets/log.csv', append=True, separator=',')\n",
    "checkpoint = ModelCheckpoint('./datasets/checkpoint.csv', monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=1, min_lr=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HYPERPARAMETERS CONSTANT\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 15\n",
    "VALIDATION_SPLIT = 0.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ValuedAcerCustomer\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6642 samples, validate on 738 samples\n",
      "Epoch 1/15\n",
      "6642/6642 [==============================] - 19s 3ms/step - loss: 0.5461 - accuracy: 0.6928 - val_loss: 0.4330 - val_accuracy: 0.7835\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.78347, saving model to ./datasets/checkpoint.csv\n",
      "Epoch 2/15\n",
      "6642/6642 [==============================] - 16s 2ms/step - loss: 0.2597 - accuracy: 0.8921 - val_loss: 0.1010 - val_accuracy: 0.9756\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.78347 to 0.97561, saving model to ./datasets/checkpoint.csv\n",
      "Epoch 3/15\n",
      "6642/6642 [==============================] - 16s 2ms/step - loss: 0.0853 - accuracy: 0.9759 - val_loss: 0.0685 - val_accuracy: 0.9821\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.97561 to 0.98211, saving model to ./datasets/checkpoint.csv\n",
      "Epoch 4/15\n",
      "6642/6642 [==============================] - 16s 2ms/step - loss: 0.0593 - accuracy: 0.9842 - val_loss: 0.0653 - val_accuracy: 0.9824\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.98211 to 0.98238, saving model to ./datasets/checkpoint.csv\n",
      "Epoch 5/15\n",
      "6642/6642 [==============================] - 16s 2ms/step - loss: 0.0445 - accuracy: 0.9874 - val_loss: 0.0635 - val_accuracy: 0.9824\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.98238\n",
      "Epoch 6/15\n",
      "6642/6642 [==============================] - 16s 2ms/step - loss: 0.0365 - accuracy: 0.9898 - val_loss: 0.0670 - val_accuracy: 0.9818\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.98238\n",
      "Epoch 7/15\n",
      "6642/6642 [==============================] - 16s 2ms/step - loss: 0.0258 - accuracy: 0.9933 - val_loss: 0.0646 - val_accuracy: 0.9848\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.98238 to 0.98482, saving model to ./datasets/checkpoint.csv\n",
      "Epoch 8/15\n",
      "6642/6642 [==============================] - 16s 2ms/step - loss: 0.0241 - accuracy: 0.9939 - val_loss: 0.0647 - val_accuracy: 0.9851\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.98482 to 0.98509, saving model to ./datasets/checkpoint.csv\n",
      "Epoch 9/15\n",
      "6642/6642 [==============================] - 17s 3ms/step - loss: 0.0239 - accuracy: 0.9939 - val_loss: 0.0647 - val_accuracy: 0.9851\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.98509\n",
      "Epoch 10/15\n",
      "6642/6642 [==============================] - 16s 2ms/step - loss: 0.0250 - accuracy: 0.9934 - val_loss: 0.0648 - val_accuracy: 0.9851\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.98509\n",
      "Epoch 11/15\n",
      "6642/6642 [==============================] - 16s 2ms/step - loss: 0.0232 - accuracy: 0.9940 - val_loss: 0.0648 - val_accuracy: 0.9851\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.98509\n",
      "Epoch 12/15\n",
      "6642/6642 [==============================] - 17s 3ms/step - loss: 0.0239 - accuracy: 0.9935 - val_loss: 0.0648 - val_accuracy: 0.9851\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.98509\n",
      "Epoch 13/15\n",
      "6642/6642 [==============================] - 16s 2ms/step - loss: 0.0236 - accuracy: 0.9941 - val_loss: 0.0648 - val_accuracy: 0.9851\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.98509\n",
      "Epoch 14/15\n",
      "6642/6642 [==============================] - 16s 2ms/step - loss: 0.0243 - accuracy: 0.9933 - val_loss: 0.0648 - val_accuracy: 0.9851\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.98509\n",
      "Epoch 15/15\n",
      "6642/6642 [==============================] - 17s 3ms/step - loss: 0.0236 - accuracy: 0.9939 - val_loss: 0.0648 - val_accuracy: 0.9851\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.98509\n"
     ]
    }
   ],
   "source": [
    "models = model.fit(X_train, y_train, \n",
    "                   batch_size=BATCH_SIZE, \n",
    "                   epochs=EPOCHS, \n",
    "                   validation_split=VALIDATION_SPLIT,\n",
    "                   callbacks=[csv_logger, reduce_lr, checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot the loss graph of the model\n",
    "plt.title('Loss')\n",
    "plt.plot(models.history['loss'], label='train')\n",
    "plt.plot(models.history['val_loss'], label='validation')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot the accuracy graph of the model\n",
    "plt.title('Accuracy')\n",
    "plt.plot(models.history['accuracy'], label='train')\n",
    "plt.plot(models.history['val_accuracy'], label='validation')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict the value of y (yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.4186697e-02, 9.9961287e-01, 9.9976152e-01, 2.2050934e-05,\n",
       "        4.5852892e-05],\n",
       "       [9.8985368e-01, 9.9992168e-01, 1.1003080e-03, 1.1099365e-03,\n",
       "        2.7551674e-04],\n",
       "       [9.9966788e-01, 1.5820212e-03, 9.9959368e-01, 2.3107775e-04,\n",
       "        1.5890342e-04],\n",
       "       ...,\n",
       "       [9.9899381e-01, 1.1925811e-03, 9.9848026e-01, 8.0672145e-04,\n",
       "        3.7975735e-03],\n",
       "       [9.9068671e-01, 9.9812263e-01, 9.5328081e-01, 3.9998449e-05,\n",
       "        2.2782044e-05],\n",
       "       [3.7515818e-03, 3.2530059e-04, 9.9938405e-01, 1.9525477e-03,\n",
       "        9.9958307e-01]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat_raw = model.predict(X_test, verbose=0)\n",
    "\n",
    "# CHECK THE NUMPY ARRAY\n",
    "yhat_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEBUG to peek at some values\n",
    "#yhat_raw[777]\n",
    "#yhat_raw[77]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1, 1, 0, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [0, 0, 1, 1, 0],\n",
       " [0, 1, 0, 0, 0],\n",
       " [1, 0, 0, 1, 0],\n",
       " [1, 0, 0, 1, 1],\n",
       " [1, 1, 0, 0, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [0, 1, 0, 1, 0],\n",
       " [1, 0, 0, 1, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [0, 1, 0, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [0, 1, 0, 0, 1],\n",
       " [0, 0, 1, 0, 0],\n",
       " [0, 0, 0, 1, 1],\n",
       " [1, 0, 1, 0, 0],\n",
       " [0, 0, 1, 0, 0],\n",
       " [0, 1, 0, 1, 0],\n",
       " [1, 0, 0, 0, 0],\n",
       " [1, 0, 0, 1, 0],\n",
       " [1, 0, 0, 0, 1],\n",
       " [1, 0, 1, 0, 0],\n",
       " [0, 0, 1, 0, 0],\n",
       " [0, 0, 0, 1, 1],\n",
       " [1, 0, 1, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [0, 0, 1, 0, 0],\n",
       " [0, 1, 0, 0, 1],\n",
       " [0, 1, 0, 1, 1],\n",
       " [1, 0, 1, 0, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [0, 0, 0, 1, 1],\n",
       " [0, 0, 1, 0, 1],\n",
       " [1, 0, 0, 1, 0],\n",
       " [0, 0, 1, 0, 0],\n",
       " [0, 1, 0, 0, 0],\n",
       " [0, 0, 1, 0, 0],\n",
       " [0, 1, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0],\n",
       " [0, 0, 1, 0, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [0, 0, 1, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [0, 0, 1, 0, 0],\n",
       " [1, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0],\n",
       " [0, 0, 0, 1, 1],\n",
       " [0, 1, 0, 0, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [0, 1, 0, 0, 1],\n",
       " [0, 0, 1, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [0, 1, 0, 0, 1],\n",
       " [1, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 1],\n",
       " [0, 1, 1, 0, 0],\n",
       " [1, 0, 0, 0, 0],\n",
       " [1, 1, 1, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [0, 1, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [0, 1, 0, 1, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [0, 1, 0, 1, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [0, 0, 1, 0, 1],\n",
       " [0, 0, 1, 0, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [0, 1, 0, 0, 1],\n",
       " [0, 0, 1, 0, 1],\n",
       " [0, 0, 1, 0, 1],\n",
       " [0, 1, 1, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [0, 0, 1, 1, 0],\n",
       " [1, 0, 0, 0, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [1, 0, 0, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [0, 0, 1, 0, 1],\n",
       " [1, 0, 1, 0, 0],\n",
       " [0, 0, 0, 1, 0],\n",
       " [0, 0, 1, 0, 0],\n",
       " [1, 0, 0, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [0, 0, 1, 1, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [0, 0, 1, 0, 1],\n",
       " [0, 1, 0, 0, 0],\n",
       " [0, 0, 1, 0, 0],\n",
       " [0, 0, 1, 0, 1],\n",
       " [0, 1, 0, 1, 0],\n",
       " [0, 0, 0, 1, 1],\n",
       " [1, 0, 0, 0, 0],\n",
       " [1, 0, 0, 1, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [0, 0, 1, 0, 0],\n",
       " [1, 0, 0, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [0, 0, 1, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [0, 0, 0, 0, 1],\n",
       " [1, 0, 0, 0, 1],\n",
       " [0, 0, 1, 0, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [1, 0, 0, 1, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 1, 1],\n",
       " [1, 0, 1, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [0, 1, 0, 0, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [1, 0, 0, 1, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 1],\n",
       " [0, 0, 1, 0, 0],\n",
       " [1, 0, 0, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [0, 0, 0, 1, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [0, 0, 1, 0, 1],\n",
       " [0, 0, 1, 1, 0],\n",
       " [1, 0, 0, 0, 1],\n",
       " [0, 1, 1, 0, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [1, 0, 0, 0, 0],\n",
       " [0, 0, 1, 1, 0],\n",
       " [1, 0, 0, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [0, 0, 1, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [0, 1, 0, 1, 0],\n",
       " [1, 0, 0, 1, 0],\n",
       " [0, 1, 0, 0, 0],\n",
       " [0, 0, 1, 1, 0],\n",
       " [0, 1, 0, 0, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [0, 0, 1, 1, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [0, 0, 0, 1, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [0, 0, 1, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [0, 0, 1, 0, 1],\n",
       " [0, 0, 0, 1, 1],\n",
       " [1, 1, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [0, 0, 1, 0, 0],\n",
       " [0, 0, 1, 1, 0],\n",
       " [0, 0, 0, 1, 1],\n",
       " [0, 0, 1, 0, 0],\n",
       " [1, 1, 1, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [0, 1, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [0, 1, 0, 1, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [0, 1, 0, 1, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [0, 1, 0, 1, 0],\n",
       " [0, 0, 1, 1, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [0, 0, 1, 0, 0],\n",
       " [0, 0, 1, 0, 0],\n",
       " [1, 0, 0, 1, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [0, 0, 0, 0, 1],\n",
       " [0, 0, 1, 1, 0],\n",
       " [0, 1, 0, 0, 1],\n",
       " [0, 1, 1, 0, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [0, 0, 1, 0, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [1, 0, 0, 1, 0],\n",
       " [0, 0, 1, 0, 0],\n",
       " [0, 1, 1, 0, 1],\n",
       " [0, 0, 0, 1, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 1, 1],\n",
       " [1, 0, 1, 0, 0],\n",
       " [0, 1, 0, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [0, 1, 0, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [0, 0, 1, 0, 0],\n",
       " [0, 1, 0, 0, 1],\n",
       " [0, 1, 1, 0, 0],\n",
       " [1, 1, 1, 0, 0],\n",
       " [1, 0, 0, 0, 1],\n",
       " [0, 0, 1, 0, 1],\n",
       " [0, 0, 0, 1, 1],\n",
       " [1, 1, 0, 0, 0],\n",
       " [1, 1, 1, 0, 0],\n",
       " [0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 1],\n",
       " [1, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 1],\n",
       " [1, 0, 1, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 1, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [0, 0, 1, 0, 1],\n",
       " [0, 0, 1, 1, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [0, 0, 1, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [1, 0, 0, 0, 0],\n",
       " [0, 0, 1, 1, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [0, 0, 1, 0, 1],\n",
       " [1, 1, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [0, 0, 1, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [1, 0, 0, 0, 1],\n",
       " [0, 1, 0, 1, 0],\n",
       " [0, 1, 0, 0, 1],\n",
       " [0, 1, 1, 0, 0],\n",
       " [0, 0, 0, 1, 0],\n",
       " [0, 1, 0, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [0, 0, 1, 1, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [0, 0, 1, 1, 0],\n",
       " [0, 1, 0, 1, 0],\n",
       " [1, 0, 0, 1, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [1, 0, 0, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [0, 1, 0, 1, 1],\n",
       " [1, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 1],\n",
       " [0, 0, 0, 1, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0],\n",
       " [0, 1, 0, 0, 1],\n",
       " [0, 1, 1, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [0, 1, 0, 0, 1],\n",
       " [1, 0, 0, 0, 0],\n",
       " [0, 0, 1, 0, 0],\n",
       " [0, 0, 1, 0, 0],\n",
       " [1, 1, 1, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [0, 1, 0, 0, 0],\n",
       " [0, 0, 1, 1, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [1, 0, 0, 1, 0],\n",
       " [1, 0, 0, 0, 1],\n",
       " [0, 0, 1, 0, 1],\n",
       " [1, 0, 1, 0, 0],\n",
       " [0, 1, 0, 0, 1],\n",
       " [0, 1, 1, 1, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [1, 0, 0, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [1, 0, 0, 0, 1],\n",
       " [1, 0, 1, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [0, 0, 1, 0, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [0, 0, 0, 0, 1],\n",
       " [0, 1, 1, 0, 0],\n",
       " [1, 1, 1, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [0, 0, 0, 1, 0],\n",
       " [0, 0, 1, 0, 1],\n",
       " [1, 0, 0, 0, 1],\n",
       " [1, 0, 0, 0, 1],\n",
       " [1, 0, 1, 0, 0],\n",
       " [0, 0, 0, 1, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [0, 1, 0, 0, 1],\n",
       " [1, 1, 0, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [0, 1, 0, 1, 0],\n",
       " [1, 0, 0, 1, 0],\n",
       " [0, 1, 1, 1, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [0, 1, 0, 1, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [1, 0, 0, 1, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [0, 0, 1, 0, 0],\n",
       " [1, 0, 0, 0, 0],\n",
       " [0, 0, 1, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [0, 0, 1, 1, 0],\n",
       " [0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 1, 0],\n",
       " [1, 0, 0, 1, 0],\n",
       " [1, 0, 0, 1, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0],\n",
       " [0, 0, 1, 1, 0],\n",
       " [0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 1, 1],\n",
       " [0, 0, 1, 0, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [0, 1, 0, 0, 1],\n",
       " [1, 1, 1, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [1, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0],\n",
       " [0, 0, 1, 0, 0],\n",
       " [0, 0, 1, 1, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [0, 1, 0, 0, 1],\n",
       " [1, 0, 0, 0, 1],\n",
       " [0, 1, 1, 0, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0],\n",
       " [0, 0, 1, 1, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [0, 1, 0, 1, 1],\n",
       " [1, 1, 0, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [0, 0, 0, 0, 1],\n",
       " [0, 1, 1, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [0, 0, 1, 0, 0],\n",
       " [0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 1, 1],\n",
       " [0, 1, 0, 0, 0],\n",
       " [1, 0, 0, 1, 0],\n",
       " [0, 0, 1, 0, 1],\n",
       " [0, 1, 1, 0, 0],\n",
       " [1, 0, 0, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [0, 0, 1, 0, 0],\n",
       " [0, 0, 1, 1, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [0, 1, 0, 1, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [0, 0, 0, 1, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [0, 0, 1, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [0, 1, 0, 0, 1],\n",
       " [1, 0, 1, 0, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [1, 0, 0, 0, 1],\n",
       " [1, 0, 0, 0, 1],\n",
       " [1, 0, 0, 1, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [0, 0, 0, 0, 1],\n",
       " [1, 0, 1, 0, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [0, 1, 0, 0, 1],\n",
       " [0, 0, 1, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [1, 1, 1, 0, 0],\n",
       " [0, 0, 0, 0, 1],\n",
       " [0, 1, 1, 0, 0],\n",
       " [0, 1, 0, 1, 0],\n",
       " [1, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [0, 0, 1, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [0, 0, 0, 0, 1],\n",
       " [1, 1, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 1, 0],\n",
       " [0, 0, 1, 0, 1],\n",
       " [0, 1, 1, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [0, 1, 0, 0, 1],\n",
       " [1, 1, 0, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [0, 0, 1, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [0, 1, 0, 1, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [1, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [0, 0, 1, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [0, 1, 1, 0, 1],\n",
       " [0, 0, 1, 0, 0],\n",
       " [0, 1, 0, 0, 1],\n",
       " [0, 0, 1, 1, 0],\n",
       " [0, 1, 0, 0, 1],\n",
       " [0, 1, 1, 0, 0],\n",
       " [0, 0, 1, 1, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [0, 0, 1, 0, 1],\n",
       " [1, 0, 0, 0, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [0, 1, 0, 0, 1],\n",
       " [0, 1, 1, 0, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [0, 0, 1, 0, 1],\n",
       " [0, 1, 1, 0, 0],\n",
       " [0, 0, 1, 0, 1],\n",
       " [0, 0, 1, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [0, 1, 0, 1, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [0, 0, 1, 0, 1],\n",
       " [0, 0, 0, 0, 1],\n",
       " [1, 0, 1, 0, 0],\n",
       " [0, 0, 1, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [1, 0, 0, 0, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 1],\n",
       " [0, 0, 1, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [0, 0, 1, 0, 0],\n",
       " [0, 0, 0, 1, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [0, 0, 0, 0, 1],\n",
       " [1, 1, 0, 0, 0],\n",
       " [1, 0, 0, 1, 0],\n",
       " [0, 0, 1, 0, 0],\n",
       " [1, 0, 0, 0, 1],\n",
       " [1, 0, 1, 0, 0],\n",
       " [0, 0, 0, 1, 1],\n",
       " [0, 1, 1, 0, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [0, 1, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [1, 0, 0, 0, 0],\n",
       " [0, 0, 1, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [0, 1, 0, 1, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [1, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [0, 1, 0, 1, 1],\n",
       " [0, 1, 1, 0, 0],\n",
       " [1, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 1],\n",
       " [0, 1, 1, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [0, 0, 0, 1, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [0, 1, 0, 1, 0],\n",
       " [1, 0, 0, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0],\n",
       " [1, 0, 0, 1, 0],\n",
       " [1, 0, 0, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [0, 1, 0, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [0, 0, 0, 1, 1],\n",
       " [0, 1, 1, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [0, 1, 0, 0, 0],\n",
       " [0, 0, 1, 0, 1],\n",
       " [1, 1, 0, 0, 0],\n",
       " [0, 1, 0, 0, 1],\n",
       " [0, 0, 1, 1, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [0, 0, 1, 1, 0],\n",
       " [1, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 1],\n",
       " [0, 0, 1, 0, 0],\n",
       " [1, 0, 0, 1, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 1],\n",
       " [0, 1, 1, 0, 0],\n",
       " [0, 0, 1, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [1, 0, 0, 1, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [1, 0, 1, 0, 1],\n",
       " [1, 0, 1, 0, 0],\n",
       " [1, 0, 0, 0, 1],\n",
       " [0, 1, 1, 0, 0],\n",
       " [0, 1, 0, 1, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [1, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 1],\n",
       " [0, 0, 1, 0, 1],\n",
       " [0, 0, 0, 0, 1],\n",
       " [1, 0, 0, 0, 1],\n",
       " [0, 1, 0, 1, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [0, 0, 0, 1, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [1, 0, 0, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [0, 1, 0, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [0, 0, 1, 0, 0],\n",
       " [1, 0, 0, 1, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [0, 0, 1, 0, 1],\n",
       " [1, 1, 0, 0, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [0, 0, 1, 1, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [1, 0, 0, 0, 0],\n",
       " [0, 0, 1, 1, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [1, 0, 0, 1, 0],\n",
       " [0, 0, 0, 1, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [0, 1, 0, 0, 1],\n",
       " [1, 0, 1, 0, 0],\n",
       " [1, 0, 0, 0, 0],\n",
       " [1, 0, 0, 1, 0],\n",
       " [1, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 1],\n",
       " [1, 1, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0],\n",
       " [0, 0, 1, 0, 0],\n",
       " [0, 1, 0, 0, 1],\n",
       " [0, 0, 1, 1, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 1],\n",
       " [0, 1, 1, 0, 0],\n",
       " [0, 0, 1, 0, 0],\n",
       " [0, 1, 0, 1, 1],\n",
       " [0, 0, 1, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [0, 1, 0, 1, 0],\n",
       " [0, 0, 1, 0, 1],\n",
       " [0, 1, 0, 0, 0],\n",
       " [0, 0, 1, 1, 0],\n",
       " [1, 0, 0, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [0, 1, 0, 0, 0],\n",
       " [1, 1, 1, 0, 0],\n",
       " [0, 1, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 1],\n",
       " [0, 0, 1, 0, 1],\n",
       " [0, 0, 0, 1, 1],\n",
       " [1, 1, 0, 0, 0],\n",
       " [1, 1, 0, 0, 1],\n",
       " [1, 1, 0, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [1, 0, 0, 1, 0],\n",
       " [0, 1, 0, 0, 1],\n",
       " [1, 1, 0, 0, 0],\n",
       " [0, 1, 0, 1, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [1, 0, 0, 0, 0],\n",
       " [0, 0, 1, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [0, 0, 1, 0, 1],\n",
       " [1, 0, 1, 0, 0],\n",
       " [0, 0, 1, 0, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [0, 1, 0, 0, 1],\n",
       " [1, 1, 0, 0, 0],\n",
       " [1, 1, 0, 1, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 1],\n",
       " [1, 0, 0, 0, 1],\n",
       " [1, 0, 1, 0, 0],\n",
       " [0, 0, 1, 0, 0],\n",
       " [0, 0, 1, 0, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [0, 0, 1, 1, 0],\n",
       " [0, 0, 1, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [0, 0, 1, 0, 1],\n",
       " [0, 1, 1, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [0, 0, 0, 0, 1],\n",
       " [0, 0, 1, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [0, 0, 1, 0, 1],\n",
       " [0, 1, 0, 1, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [0, 0, 1, 1, 0],\n",
       " [0, 0, 1, 1, 0],\n",
       " [0, 0, 0, 1, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [0, 0, 1, 0, 0],\n",
       " [0, 1, 0, 0, 1],\n",
       " [0, 1, 1, 0, 0],\n",
       " [0, 0, 1, 0, 1],\n",
       " [1, 0, 0, 0, 1],\n",
       " [0, 0, 0, 1, 1],\n",
       " [0, 1, 0, 0, 0],\n",
       " [0, 0, 1, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0],\n",
       " [1, 0, 0, 0, 1],\n",
       " [1, 0, 0, 0, 1],\n",
       " [1, 0, 0, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [1, 0, 0, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [0, 0, 1, 0, 1],\n",
       " [1, 0, 1, 0, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [0, 0, 1, 0, 0],\n",
       " [0, 0, 0, 1, 0],\n",
       " [1, 0, 0, 1, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [0, 1, 0, 1, 0],\n",
       " [0, 0, 1, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [0, 0, 1, 0, 1],\n",
       " [1, 0, 0, 0, 1],\n",
       " [0, 1, 1, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [1, 0, 0, 1, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [0, 1, 0, 0, 1],\n",
       " [0, 0, 1, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [1, 0, 1, 0, 1],\n",
       " [0, 0, 1, 0, 1],\n",
       " [0, 0, 1, 0, 0],\n",
       " [0, 1, 0, 1, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [1, 1, 1, 0, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [0, 0, 0, 1, 1],\n",
       " [1, 0, 0, 0, 0],\n",
       " [1, 1, 1, 0, 0],\n",
       " [0, 0, 1, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [0, 0, 1, 1, 0],\n",
       " [0, 0, 1, 0, 0],\n",
       " [1, 0, 0, 0, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [1, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0],\n",
       " [0, 1, 0, 1, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [0, 0, 1, 0, 0],\n",
       " [0, 0, 1, 0, 1],\n",
       " [0, 1, 1, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [1, 0, 0, 0, 1],\n",
       " [0, 0, 1, 1, 0],\n",
       " [0, 1, 0, 0, 0],\n",
       " [1, 0, 0, 0, 1],\n",
       " [0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 1, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [0, 0, 0, 0, 1],\n",
       " [0, 0, 1, 0, 1],\n",
       " [1, 0, 0, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [0, 0, 1, 0, 0],\n",
       " [0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 1, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [1, 1, 0, 0, 1],\n",
       " [0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 1],\n",
       " [1, 1, 0, 0, 0],\n",
       " [0, 1, 0, 1, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [1, 0, 0, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [1, 1, 1, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [0, 0, 1, 0, 1],\n",
       " [0, 1, 1, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [0, 0, 1, 1, 0],\n",
       " [1, 0, 0, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [1, 0, 0, 1, 0],\n",
       " [0, 1, 0, 0, 1],\n",
       " [0, 1, 1, 0, 0],\n",
       " [0, 0, 0, 1, 0],\n",
       " [0, 1, 0, 0, 1],\n",
       " [0, 0, 1, 0, 1],\n",
       " [0, 0, 1, 0, 0],\n",
       " [0, 0, 1, 0, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [0, 0, 1, 1, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [0, 0, 1, 0, 0],\n",
       " [1, 1, 0, 1, 0],\n",
       " [0, 0, 1, 0, 1],\n",
       " [1, 0, 0, 1, 0],\n",
       " [0, 0, 1, 0, 1],\n",
       " [0, 1, 1, 0, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [0, 0, 0, 1, 1],\n",
       " [1, 0, 1, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [0, 0, 0, 0, 1],\n",
       " [0, 0, 1, 0, 1],\n",
       " [0, 1, 1, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [1, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [0, 0, 0, 0, 1],\n",
       " [1, 0, 0, 0, 1],\n",
       " [1, 0, 1, 0, 0],\n",
       " [0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 1, 1],\n",
       " [0, 0, 1, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0],\n",
       " [0, 1, 0, 1, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [0, 1, 0, 1, 0],\n",
       " [0, 0, 0, 1, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [0, 0, 1, 0, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [0, 0, 1, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [0, 0, 1, 0, 1],\n",
       " [0, 1, 1, 0, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0],\n",
       " [0, 0, 1, 0, 1],\n",
       " [1, 0, 0, 1, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 1, 0],\n",
       " [1, 0, 0, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [1, 1, 1, 0, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [0, 0, 1, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [0, 0, 1, 0, 0],\n",
       " [0, 0, 1, 1, 0],\n",
       " [0, 0, 1, 1, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [1, 0, 0, 1, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [0, 0, 1, 0, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [0, 1, 0, 0, 0],\n",
       " [0, 1, 1, 1, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [1, 0, 0, 0, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [0, 0, 1, 0, 1],\n",
       " [0, 0, 1, 1, 0],\n",
       " [0, 1, 0, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [1, 0, 0, 0, 1],\n",
       " [0, 0, 0, 1, 1],\n",
       " [0, 1, 1, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [1, 0, 0, 1, 0],\n",
       " [1, 0, 0, 0, 1],\n",
       " [0, 1, 1, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [0, 0, 0, 1, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [0, 0, 0, 0, 1],\n",
       " [1, 0, 0, 0, 1],\n",
       " [0, 1, 1, 0, 0],\n",
       " [0, 0, 1, 1, 0],\n",
       " [0, 0, 0, 1, 1],\n",
       " [0, 1, 1, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [0, 0, 1, 0, 1],\n",
       " [1, 0, 1, 1, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [0, 1, 0, 1, 0],\n",
       " [1, 0, 0, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [0, 1, 0, 0, 1],\n",
       " [0, 1, 1, 0, 0],\n",
       " [0, 0, 1, 0, 0],\n",
       " [0, 0, 0, 1, 1],\n",
       " [0, 1, 0, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [0, 0, 1, 1, 0],\n",
       " [0, 0, 1, 0, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [1, 0, 1, 1, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [0, 0, 1, 0, 1],\n",
       " [1, 0, 0, 0, 1],\n",
       " [0, 1, 1, 0, 0],\n",
       " [0, 1, 0, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [0, 0, 1, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [1, 0, 0, 0, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [1, 0, 1, 0, 0],\n",
       " [0, 0, 1, 0, 0],\n",
       " [1, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 1],\n",
       " [0, 0, 1, 0, 0],\n",
       " [0, 0, 1, 0, 1],\n",
       " [1, 1, 0, 0, 0],\n",
       " [0, 1, 0, 0, 1],\n",
       " [1, 0, 1, 0, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " ...]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CONVERT PREDICTIONS INTO DISCRETE CLASSIFIER (0 OR 1)\n",
    "# TOLERANCE CONSTANT\n",
    "TOLERANCE = 0.5\n",
    "\n",
    "# predicting crisp classes for test set\n",
    "yhat = [[1 if x > TOLERANCE else 0 for idx,x in enumerate(i)] for i in yhat_raw]\n",
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEBUG to peek at some values\n",
    "#yhat[777]\n",
    "#yhat[77]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outwear</th>\n",
       "      <th>top</th>\n",
       "      <th>trousers</th>\n",
       "      <th>women dresses</th>\n",
       "      <th>women skirts</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2455</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2456</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2457</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2458</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2459</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2460 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      outwear  top  trousers  women dresses  women skirts\n",
       "id                                                       \n",
       "0           0    1         1              0             0\n",
       "1           1    1         0              0             0\n",
       "2           1    0         1              0             0\n",
       "3           0    1         1              0             0\n",
       "4           0    1         1              0             0\n",
       "...       ...  ...       ...            ...           ...\n",
       "2455        0    0         1              1             0\n",
       "2456        1    0         1              0             0\n",
       "2457        1    0         1              0             0\n",
       "2458        1    1         1              0             0\n",
       "2459        0    0         1              0             1\n",
       "\n",
       "[2460 rows x 5 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CONVERT THE YHAT VALUES INTO A PANDAS DATAFRAME\n",
    "yhat_df = pd.DataFrame(yhat,index=fashion_test_df['id'],columns=train_labels)\n",
    "yhat_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export the predictions as a .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSERT FILE NAME\n",
    "FILENAME = 'TEAM_MIA_nlp_predictions'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPORT THE CSV FILE\n",
    "yhat_df.to_csv('./datasets/{}.csv'.format(FILENAME), index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
